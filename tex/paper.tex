\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

\usepackage[final]{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{color}

\usepackage{algorithm}
\usepackage{algpseudocode}

\newcommand{\glnote}[1]{\textcolor{red}{[GL: #1]}}

\title{Adversarial Training of Neural Networks\\
against Systematic Uncertainty}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Gilles Louppe \\
  New York University\\
  \texttt{g.louppe@nyu.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\glnote{Distinction between statistical and systematic uncertainty.}
\glnote{Define nuisance parameters.}
\glnote{We want to build an accurate classifier whose output remains invariant with
respect to systematic uncertainties.}
% https://www.slac.stanford.edu/econf/C030908/papers/TUAT004.pdf
\glnote{Motivate the criterion (which may not be obvious for the ML crowd). See pivotal quantity motivation.}



\section{Problem statement}
\label{sec:problem}

Let assume a probability space $(\Omega, {\cal F}, P)$, where $\Omega$ is a
sample space, ${\cal F}$ is a set of events and $P$ is a probability measure.
Let consider the multivariate random variables $X_z: \Omega \mapsto
\mathbb{R}^p$ and $Y: \Omega \mapsto {\cal Y}$, where $X_z$ denotes a dependence on a
nuisance parameter $Z$ whose values $z \in {\cal Z}$  define a
parameterized family of its systematic uncertainties. That is, $X_z$ and
$Y$ induce together a joint probability distribution $p(X,Y|z)$, where the
conditional on $z$ denotes $X_z$. For training, let further assume a
finite set $\{ x_i, y_i, z_i \}_{i=1}^N$ of realizations
$X_{z_i}(\omega_i), Y(\omega_i)$, for $\omega_i \in \Omega$ and known
values $z_i$ of the nuisance parameter. Our goal is to learn a function
$f(\cdot;\theta_f) : \mathbb{R}^p \mapsto {\cal Y}$ of parameters $\theta_f$
(e.g., a neural network-based classifier if ${\cal Y}$ is a finite set of
classes) and minimizing  a loss ${\cal L}_f(\theta_f)$. In addition, we require
that $f(X_z ; \theta_f)$ should be robust to the value $z$ of the nuisance parameter  --
which remains unknown at test time. More specifically, we aim at building $f$
such that in the ideal case
\begin{equation}\label{eqn:criterion-true}
f(X_{z}(\omega) ; \theta_f) = f(X_{z^\prime}(\omega) ; \theta_f)
\end{equation} for all
samples $\omega \in \Omega$ and all $z, z^\prime$ pairs of values of the
nuisance parameter.

Since we do not have training tuples $(X_{z}(\omega),
X_{z^\prime}(\omega))$ (for the same unknown $\omega$), we propose instead to
solve the closely related problem of finding a predictive function $f$ such that
\begin{equation}\label{eqn:criterion-measure}
    P(\{ \omega | f(X_{z}(\omega) ; \theta_f) = y \} ) = P( \{ \omega' | f(X_{z^\prime}(\omega') ; \theta_f) = y\}) \text{ for all $y \in {\cal Y}$}.
\end{equation}
In words, we are looking for a predictive function $f$ which is a pivotal
quantity \citep{degroot1986probability} with respect to the nuisance parameter.
That is, such that  the distribution of $f(X_z; \theta_f)$ is invariant
with respect to the value $z$ of the nuisance. Note that a function $f$ for which
Eqn.~\ref{eqn:criterion-true} is true necessarily satisfies
Eqn.~\ref{eqn:criterion-measure}. The converse is however in general not true, since the
sets of samples $\{ \omega | f(X_{z}(\omega); \theta_f) = y \}$ and $\{
\omega' | f(X_{z^\prime}(\omega'); \theta_f) = y \}$ do not need to be the same
for the equality to hold.
In order to simplify notations,
and as only Eqn.~\ref{eqn:criterion-measure} is
of direct interest in this work, we denote from here on
the pivotal quantity criterion as
\begin{equation}\label{eqn:criterion}
    p(f(X ; \theta_f) | z ) = p(f(X ; \theta_f) | z^\prime ) \text{ for all $z,z^\prime \in  {\cal Z}$.}
\end{equation}


\section{Method}
\label{sec:method}

Adversarial training was first proposed by \cite{goodfellow2014generative} as a
way to build a generative model capable of producing samples from random noise
$z \sim p_Z$. More specifically, the authors pit a generative model $g: {\cal Z}
\mapsto \mathbb{R}^p$ against an adversary classifier $d : \mathbb{R}^p \mapsto \{
0, 1\}$ whose antagonistic objective is to recognize real data $X$ from generated data $g(Z)$. Both
models $g$ and $d$ are trained simultaneously, in such a way that $g$ learns to
produce samples that are difficult to identify by $d$, while $d$ incrementally
adapts to changes in $g$. At the equilibrium, $g$ models a distribution whose
samples can be identified by $d$ only by chance. That is, assuming enough
capacity in $d$ and  $g$, the distribution $p_{g(Z)}$ eventually converges
towards the real distribution $p_X$.

In this work, we repurpose adversarial training as a means to constraint the
predictive model $f$ in order to satisfy Eqn.~\ref{eqn:criterion}. In
particular, we pit $f$ against an adversary classifier $r(\cdot ;
\theta_r) : \mathbb{R} \mapsto {\cal Z}$ of parameters $\theta_r$ and
associated loss ${\cal L}_r(\theta_f, \theta_r)$.
Assuming that ${\cal Z}$ defines a finite family of nuisance values $z_l$ (for $l=1, \dots, |{\cal Z}|$),
this classifier takes as input realizations of $f(X; \theta_f)$, for the current value $\theta_f$ of $f$ parameters,
and produces as output probability estimates $r(f(X; \theta_f); \theta_r)_l = \hat{p}(z_l| f(X; \theta_f)) $
that $f(X; \theta_f)$ is generated from the nuisance value $z_l$. If $p(f(X; \theta_f)|z)$ varies with $z$,
then the corresponding correlation can be captured by $r$. By contrast, if
$p(f(X; \theta_f)|z)$ is invariant with $z$, as we require, then $r$
should perform poorly and be close to random guessing. Training $f$ such that it additionally minimizes the performance of $r$
therefore acts as a regularization towards Eqn.~\ref{eqn:criterion}.

As for generative adversarial networks, we propose to
train $f$ and $r$ simultaneously, which we carry out by considering
the value function
\begin{equation}
    E(\theta_f, \theta_r) = {\cal L}_f(\theta_f) - {\cal L}_r(\theta_f, \theta_r)
\end{equation}
that we optimize by finding the saddle point $(\smash{\hat\theta_f}, \smash{\hat\theta_r})$ such that
\begin{align}
    \smash{\hat\theta_f} &= \arg \min_{\theta_f} E(\theta_f, \smash{\hat\theta_r}), \label{eqn:min_thetaf} \\
    \smash{\hat\theta_r} &= \arg \max_{\theta_r} E(\smash{\hat\theta_f}, \theta_r) \label{eqn:max_thetar}.
\end{align}
The adversarial training procedure to obtain $(\smash{\hat\theta_f},
\smash{\hat\theta_r})$ is formally presented in
Algorithm~\ref{alg:adversarial-training} in the case of $f$ being a classifier
and of the cross-entropy loss for both ${\cal L}_f$ and ${\cal L}_r$. The algorithm
consists in using stochastic gradient descent alternatively to optimize
Eqn.~\ref{eqn:min_thetaf} and \ref{eqn:max_thetar}.

\begin{algorithm}
\caption{Adversarial training of a classifier $f$ against an adversary $r$.\\
{\it Inputs:} training data $\{ x_i, y_i, z_i \}_{i=1}^N$\\
{\it Outputs:} $\smash{\hat\theta_f}, \smash{\hat\theta_r}$\\
{\it Hyper-parameters:} Number $T$ of training iterations, Number $K$ of gradient steps to update $r$.}
\label{alg:adversarial-training}
\begin{algorithmic}[1]
    \For{$t=1$ to $T$}
        \For{$k=1$ to $K$} \Comment{Update $r$}
            \State{Sample minibatch $\{x_m, z_m \}_{m=1}^M$} of size $M$;
            \State{With $\theta_f$ fixed, update $r$ by ascending its stochastic gradient $\nabla_{\theta_r} E(\theta_f, \theta_r) :=$
            $$\nabla_{\theta_r} \sum_{m=1}^M \left[\sum_{z_l \in {\cal Z}} 1(z_m = z_l)\log r(f(x_m;\theta_f);\theta_r)_l \right];$$}
        \EndFor
        \State{Sample minibatch $\{x_m, y_m, z_m \}_{m=1}^M$} of size $M$; \Comment{Update $f$}
        \State{With $\theta_r$ fixed, update $f$ by descending its stochastic gradient $\nabla_{\theta_f} E(\theta_f, \theta_r) :=$
        $$\nabla_{\theta_f}  \sum_{m=1}^M \left[ -\sum_{y_c \in {\cal Y}} 1(y_m = y_c) \log f(x_m;\theta_f)_c  +\sum_{z_l \in {\cal Z}} 1(z_m = z_l)\log r(f(x_m;\theta_f);\theta_r)_l \right];$$}
    \EndFor
\end{algorithmic}
\end{algorithm}


\section{Theoretical results}

In this section, we show that in the setting of
Algorithm~\ref{alg:adversarial-training}, the procedure converges to a
classifier $f$ which is a pivotal quantity in the sense of
Eqn.~\ref{eqn:criterion}. Results below are derived in a non-parametric setting,
by assuming that both $f$ and $r$ have enough capacity. To simplify the
presentation, we also assume the uniform prior $p(z) =
\frac{1}{|{\cal Z}|}$ for all $z \in {\cal Z}$, e.g. by having the same
number of training samples for each modality $z$ of the nuisance
parameter.


\begin{proposition}\label{prop:1}

Let $\theta_f$ be fixed and $\hat\theta_r = \arg \max_{\theta_r} E(\theta_f,
\theta_r)$. If $r(f(X;\theta_f) ; \hat\theta_r )_l = \frac{1}{|{\cal Z}|}$
for all $z_l$, then $f$ is a pivotal quantity.

\end{proposition}

\begin{proof}

Let us first recall that the cross-entropy for distributions $p$ and $q$ is
minimized when $p=q$. For ${\cal L}_r$ defined as the cross-entropy between the
true conditional distribution of the nuisance $p_{Z|f(X;\theta_f)}$ and
the approximate conditional distribution of the nuisance
$p_{r(f(X;\theta_f);\theta_r)|f(X)}$, the optimal parameters $\smash{\hat\theta}_r =
\arg \max_{\theta_r} E(\theta_f, \theta_r) = \arg \min_{\theta_r} L_r(\theta_f,
\theta_r)$ are therefore such that $p_{r(f(X;\theta_f);\hat\theta_r)|f(X)} = p_{Z|f(X;\theta_f)}$.

In other words, for all $z_l \in {\cal Z}$, we have $r(f(X;\theta_f);\smash{\hat\theta}_r)_l = p(z_l|f(X;\theta_f))$.
By assumption, $r(f(X;\theta_f);\smash{\hat\theta}_r)_l = \frac{1}{|{\cal Z}|}$,
and therefore $p(z_l|f(X;\theta_f)) = \frac{1}{|{\cal Z}|}$.
Using the Bayes' rule, we write
\begin{align*}
    p(f(X;\theta_f)|z_l) &= \frac{ p(z_l|f(X;\theta_f)) p(f(X;\theta_f)) } { p(z_l)} \\
                         &= \frac{ \tfrac{1}{|{\cal Z}|} p(f(X;\theta_f)) } { \tfrac{1}{|{\cal Z}|} } \\
                         &= p(f(X;\theta_f)),
\end{align*}
which holds for all $z_l \in {\cal Z}$ and implies that $f$ is a pivotal quantity.
\end{proof}

\begin{proposition}\label{prop:2}

If there exists a saddle point $(\smash{\hat\theta}_f, \smash{\hat\theta}_r)$
for Eqn.~\ref{eqn:min_thetaf} and \ref{eqn:max_thetar} such that
$E(\hat\theta_f, \hat\theta_r) = H(p_{Y|X}) - \log |{\cal Z}|$, then
$f(\cdot;\smash{\hat\theta}_f)$ is both an optimal classifier with respect to
$L_f$ and a pivotal quantity.

\end{proposition}

\begin{proof}

For fixed $\theta_f$, the adversary $r$ is optimal at $\hat\theta_r = \arg
\max_{\theta_r} E(\theta_f, \theta_r)  = \arg \min_{\theta_r} L_r(\theta_f,
\theta_r)$, in which case $p_{r(f(X;\theta_f);\hat\theta_r)|f(X)} = p_{Z|f(X;\theta_f)}$ and $L_r$ reduces to the entropy
$H(p_{Z|f(X;\theta_f)})$ of the conditional distribution of the nuisance. The
value function $E$ can therefore be rewritten as $$E'(\theta_f) = L_f(\theta_f) -
H(p_{Z|f(X;\theta_f)}).$$  In particular, we have the lower bound $H(p_{Y|X}) -
\log |{\cal Z}| \leq L_f(\theta_f) - H(p_{Z|f(X;\theta_f)})$ where the equality
holds at $\smash{\hat\theta}_f = \arg \min_{\theta_f} E'(\theta_f)$ only when
\begin{itemize}
    \item $\smash{\hat\theta}_f$ corresponds to
    the parameters of an optimal classifier, in which case the log-loss $L_f$
    reduces to $H(p_{Y|X})$,
    \item all
   outcomes of $Z|f(X;\smash{\hat\theta}_f)$ are equally likely, in which case
   $p(z_l|f(X;\smash{\hat\theta}_f)) = \frac{1}{|{\cal Z}|}$ for all $z_l \in {\cal
   Z}$ and $H(p_{Z|f(X;\smash{\hat\theta}_f)}) =
   -\sum_{z_l \in {\cal Z}} p(z|\smash{\hat\theta}_f) \log  p(z|\smash{\hat\theta}_f) =  -\sum_{z_l \in {\cal Z}} \frac{1}{|{\cal Z}|} \log \frac{1}{|{\cal Z}|} = \log |{\cal Z}|$.
\end{itemize}
Accordingly, the second condition implies that $r(f(X;\smash{\hat\theta}_f) ;
\smash{\hat\theta}_r )_l = \frac{1}{|{\cal Z}|}$ and therefore that at this
point, because of Proposition~\ref{prop:1}, the optimal classifier $f(\cdot;\smash{\hat\theta}_f)$ is also a pivotal quantity.
\end{proof}

\glnote{We should further discuss that in practice, the equality may never hold.
We should discuss in which circumstances. In such case, the pivotal quantity
constraint can however be enforced by outweighting the $L_r$, resulting in a
trade-off between classifier optimality and pivotality.}

\begin{proposition}
    \glnote{It remains to prove that the procedure of Algorithm 1
    converges towards that saddle point. The proof should be similar to the proof of convergence in the GAN paper.}
\end{proposition}

\section{Experiments}

\section{Related work}

\glnote{Similar to domain adaptation, but with infinitely many domains,
as parameterized by $Z$, also related to transfer learning.}

\section{Conclusions}

\subsubsection*{Acknowledgments}

\bibliographystyle{ieeetr}
{\small
\bibliography{bibliography.bib}}

\end{document}
