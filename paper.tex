\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

\usepackage[final]{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{color}

\newcommand{\glnote}[1]{\textcolor{red}{[GL: #1]}}

\title{Adversarial Training of Neural Networks\\
against Systematic Uncertainty}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Gilles Louppe \\
  New York University\\
  \texttt{g.louppe@nyu.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\glnote{Distinction between statistical and systematic uncertainty.}
\glnote{Define nuisance parameters.}
\glnote{We want to build an accurate classifier whose output remains invariant with
respect to systematic uncertainties.}
% https://www.slac.stanford.edu/econf/C030908/papers/TUAT004.pdf
\glnote{Motivate the criterion (which may not be obvious for the ML crowd).}



\section{Problem statement}
\label{sec:problem}

Let assume a probability space $(\Omega, {\cal F}, P)$, where $\Omega$ is a
sample space, ${\cal F}$ is a set of events and $P$ is a probability measure.
Let consider the multivariate random variables $X_\lambda: \Omega \mapsto
\mathbb{R}^p$ and $Y: \Omega \mapsto {\cal Y}$, where $X_\lambda$ depends on a
nuisance parameter $\lambda \in \mathbb{R}$ whose values define a continuously
parameterized family of its systematic uncertainties. That is, $X_\lambda$ and
$Y$ induce together a joint probability distribution $p(X,Y|\lambda)$, where the
conditional on $\lambda$ denotes $X_\lambda$. For training, let further assume a
finite set $\{ x_i, y_i, \lambda_i \}_{i=1}^N$ of realizations
$X_{\lambda_i}(\omega_i), Y(\omega_i)$, for $\omega_i \in \Omega$ and known
values $\lambda_i$ of the nuisance parameter. Our goal is to learn a function
$f(\cdot;\theta_f) : \mathbb{R}^p \mapsto {\cal Y}$ of parameters $\theta_f$
(e.g., a neural network-based classifier if ${\cal Y}$ is a finite set of
classes) and minimizing  a loss ${\cal L}_f(\theta_f)$. In addition, we require
that $f(X_\lambda ; \theta_f)$ should be robust to the value of the nuisance parameter $\lambda$ --
which remains unknown at test time. More specifically, we aim at building $f$
such that in the ideal case
\begin{equation}\label{eqn:criterion-true}
f(X_{\lambda_i}(\omega) ; \theta_f) = f(X_{\lambda_j}(\omega) ; \theta_f)
\end{equation} for any
sample $\omega \in \Omega$ and any $\lambda_i, \lambda_j$ pair of values of the
nuisance parameter.

Since we do not have training tuples $(X_{\lambda_i}(\omega),
X_{\lambda_j}(\omega))$ (for the same unknown $\omega$) \glnote{Actually we do, as discussed with Michael!}, we propose instead to
solve the closely related problem of finding a predictive function $f$ such that
\begin{equation}\label{eqn:criterion}
    P(\{ \omega | f(X_{\lambda_i}(\omega) ; \theta_f) = y \} ) = P( \{ \omega' | f(X_{\lambda_j}(\omega') ; \theta_f) = y\}) \text{ for all $y \in {\cal Y}$}.
\end{equation}
In words, we are looking for a predictive function $f$ such that  the
distribution of $f(X_\lambda; \theta_f)$ is invariant with respect to the nuisance
parameter $\lambda$. Note that a function $f$ for which Eqn.~\ref{eqn:criterion-true} is
true necessarily satisfies Eqn.~\ref{eqn:criterion}. The converse is however in
general not true, since the sets of samples $\{ \omega | f(X_{\lambda_i}(\omega); \theta_f) = y \}$
and $\{ \omega' | f(X_{\lambda_j}(\omega'); \theta_f) = y \}$ do not need to be the same
for the equality to hold.

\glnote{An alternative objective, but which leads to something
significantly different, is to aim at getting the best model adapted
to the unknown $\lambda$, possibly using predictive information from
regions of the input space affected by the nuisance parameter.}


\section{Method}
\label{sec:method}

Adversarial training was first proposed by \cite{goodfellow2014generative} as a
way to build a generative model capable of producing samples from random noise
$z \sim p_Z$. More specifically, the authors pit a generative model $g: {\cal Z}
\mapsto \mathbb{R}^p$ against an adversary classifier $d : \mathbb{R}^p \mapsto \{
0, 1\}$ whose antagonistic objective is to recognize real data $X$ from generated data $g(Z)$. Both
models $g$ and $d$ are trained simultaneously, in such a way that $g$ learns to
produce samples that are difficult to identify by $d$, while $d$ incrementally
adapts to changes in $g$. At the equilibrium, $g$ models a distribution whose
samples can be identified by $d$ only by chance. That is, assuming enough
capacity in $d$ and  $g$, the distribution $p_{g(Z)}$ eventually converges
towards the real distribution $p_X$.

In this work, we repurpose adversarial training as a means to regularize the
predictive model $f$ in order to satisfy Eqn.~\ref{eqn:criterion}. In
particular, we pit $f$ against an adversary regression model $r(\cdot ;
\theta_r) : \mathbb{R} \mapsto \mathbb{R}$ of parameters $\theta_r$ and
associated loss ${\cal L}_r(\theta_r)$. This regressor takes as input realizations of $f(X_\lambda; \theta_f)$
and produces as output predictions $\smash{\hat\lambda} = r(f(X_\lambda; \theta_f))$
of the nuisance parameter. If $p(f(X_\lambda; \theta_f))$ varies with $\lambda$,
then the corresponding correlation can be captured by $r$. By contrast, if
$p(f(X_\lambda; \theta_f))$ is invariant with $\lambda$ as we require, then $r$
should perform poorly. Training $f$ such that it additionally minimizes the performance of $r$
therefore acts as a regularization towards Eqn.~\ref{eqn:criterion}.

As for generative adversarial networks, we propose to
train $f$ and $r$ simultaneously, which we carry out by considering
the value function
\begin{equation}
    E(\theta_f, \theta_r) = {\cal L}_f(\theta_f) - {\cal L}_r(\theta_r)
\end{equation}
that we optimize by finding the saddle point $(\smash{\hat\theta_f}, \smash{\hat\theta_r})$ such that
\begin{align}
    \smash{\hat\theta_f} &= \arg \min_{\theta_f} E(\theta_f, \smash{\hat\theta_r}), \\
    \smash{\hat\theta_r} &= \arg \max_{\theta_r} E(\smash{\hat\theta_f}, \theta_r).
\end{align}

\glnote{Expand the equation to make it clearer that $f$ is plugged into $r$.}
\glnote{Explain this can be done simply using SGD.}
\glnote{What are the necessary conditions on ${\cal L}_r$ to imply
Eqn.~\ref{eqn:criterion} at the saddle point? We should clarify and prove that
formally! There may also be assumptions required on the learning problem itself.}

\section{Experiments}

\section{Related work}

\glnote{Similar to domain adaptation, but with infinitely many domains,
as parameterized by $\lambda$, also related to transfer learning.}

\section{Conclusions}

\subsubsection*{Acknowledgments}

\bibliographystyle{ieeetr}
{\small
\bibliography{bibliography.bib}}

\end{document}
